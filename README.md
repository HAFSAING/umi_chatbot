# ğŸ¤– UMI RAG Chatbot

Un chatbot intelligent avec RAG (Retrieval-Augmented Generation) qui peut analyser vos documents PDF et traiter des images.

## ğŸš€ Installation Rapide

### PrÃ©requis
- Python 3.8+
- [Ollama](https://ollama.ai/) installÃ© et dÃ©marrÃ©

### 1. Cloner et configurer
```bash
cd backend/
python setup.py
```

### 2. Installer les modÃ¨les Ollama requis
```bash
ollama pull llama3.2        # ModÃ¨le de langage principal
ollama pull llava:latest    # Pour l'analyse d'images
ollama pull nomic-embed-text # Pour les embeddings
```

### 3. Ajouter vos documents PDF
```bash
# Copiez vos fichiers PDF dans le dossier
cp vos-documents.pdf data/documents/
```

### 4. DÃ©marrer le serveur
```bash
python app.py
```

### 5. Ouvrir l'interface
Ouvrez `frontend/chatbot.html` dans votre navigateur

## ğŸ“ Structure du Projet

```
mon-projet-umi/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # Serveur Flask principal
â”‚   â”œâ”€â”€ setup.py            # Script d'installation
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ loader.py       # Chargeur de PDFs
â”‚   â”‚   â”œâ”€â”€ vector_db.py    # Base vectorielle
â”‚   â”‚   â””â”€â”€ retriever.py    # Recherche RAG
â”‚   â”‚
â”‚   â””â”€â”€ memory/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ manager.py      # Gestion mÃ©moire
â”‚       â””â”€â”€ visualizer.py   # Visualisation
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ chatbot.html        # Interface utilisateur
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/          # ğŸ“š AJOUTEZ VOS PDFs ICI
â”‚   â”œâ”€â”€ vector_db/          # Base vectorielle (auto-gÃ©nÃ©rÃ©e)
â”‚   â””â”€â”€ memory/             # Historique conversations
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Variables d'environnement
CrÃ©ez un fichier `.env` (optionnel) :
```env
OLLAMA_HOST=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
CHAT_MODEL=llama3.2
VISION_MODEL=llava:latest
```

### ModÃ¨les Ollama supportÃ©s
- **Langage** : llama3.2, llama3, llama2, mistral
- **Vision** : llava:latest, llava:7b, llava:13b
- **Embeddings** : nomic-embed-text, all-minilm

## ğŸ’¡ Utilisation

### Chat Textuel avec RAG
1. Ajoutez vos PDFs dans `data/documents/`
2. Le chatbot analysera automatiquement le contenu
3. Posez des questions sur vos documents

### Analyse d'Images
1. Cliquez sur l'icÃ´ne ğŸ“·
2. SÃ©lectionnez une image
3. Le modÃ¨le llava analysera l'image

### Commandes Vocales
1. Cliquez sur l'icÃ´ne ğŸ¤
2. Parlez (nÃ©cessite un navigateur compatible)
3. Votre voix sera transcrite

## ğŸ› ï¸ API Endpoints

```bash
# Statut du systÃ¨me
GET /api/status

# Chat avec RAG
POST /api/chat
{
    "message": "Votre question",
    "image": "base64_image_data"  // optionnel
}

# RÃ©initialiser RAG
POST /api/initialize-rag
```

## ğŸ” RÃ©solution de ProblÃ¨mes

### âŒ "Ollama non connectÃ©"
```bash
# VÃ©rifier qu'Ollama fonctionne
ollama list

# RedÃ©marrer Ollama
ollama serve
```

### âŒ "ModÃ¨le llava non disponible"
```bash
# Installer le modÃ¨le
ollama pull llava:latest
```

### âŒ "Aucun contexte RAG trouvÃ©"
```bash
# VÃ©rifier les PDFs
ls data/documents/*.pdf

# RÃ©initialiser la base vectorielle
curl -X POST http://localhost:5000/api/initialize-rag
```

### âŒ "Failed to fetch"
- VÃ©rifiez que le serveur Flask fonctionne sur le port 5000
- VÃ©rifiez les CORS si vous utilisez un autre domaine

## ğŸ¯ FonctionnalitÃ©s

- âœ… **RAG intelligent** : Analyse de documents PDF
- âœ… **Vision** : Analyse d'images avec llava
- âœ… **MÃ©moire** : Historique des conversations
- âœ… **Interface moderne** : Chat responsive
- âœ… **Voice input** : Reconnaissance vocale
- âœ… **Multi-modal** : Texte + Images
- âœ… **RÃ©ponses rapides** : Quick replies contextuelles

## ğŸš€ DÃ©veloppement

### Ajouter de nouveaux formats
Modifiez `rag/loader.py` pour supporter d'autres formats :
```python
# Exemple pour Word, Excel, etc.
from langchain_community.document_loaders import Docx2txtLoader
```

### Personnaliser le modÃ¨le
Changez le modÃ¨le dans `app.py` :
```python
model_name = "mistral"  # ou votre modÃ¨le prÃ©fÃ©rÃ©
```

### Debug mode
```bash
# DÃ©marrer en mode debug
python app.py --debug
```

## ğŸ“Š Monitoring

### Visualiser l'historique
```python
from backend.memory.visualizer import MemoryVisualizer
viz = MemoryVisualizer()
viz.show_conversations(limit=10)
```

### VÃ©rifier la base vectorielle
```python
from backend.rag.vector_db import VectorDB
db = VectorDB()
# Compter les documents indexÃ©s
print(f"Documents: {db.vectorstore._collection.count()}")
```


## ğŸ“ Licence

MIT License - voir le fichier LICENSE

## ğŸ†˜ Support

- ğŸ“§ Email: support@umi.com
- ğŸ“± Issues GitHub
- ğŸ’¬ Discord Community

---

**Fait avec â¤ï¸ pour UMI**